{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f730628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os \n",
    "\n",
    "# Add the project root to the Python path \n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..')) \n",
    "if project_root not in sys.path: \n",
    "    sys.path.insert(0, project_root) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06863097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from omegaconf import DictConfig\n",
    "from models import GraphTransformer\n",
    "from torch.nn import TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c087840",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = DictConfig({\n",
    "        'model': {\n",
    "            'self_attention_layer': 2,\n",
    "            'readout': 'mean'  # Options: 'concat', 'sum', 'mean', 'max'\n",
    "        },\n",
    "        'dataset': {\n",
    "            'node_sz': 10,\n",
    "            'node_feature_sz': 32\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "835bd07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphTransformer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7171dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTransformer(\n",
       "  (attention_list): ModuleList(\n",
       "    (0-1): 2 x TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=32, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=1024, out_features=32, bias=True)\n",
       "      (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=32, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14ca3469",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_timesteps = 50  # Placeholder, as it's not used in the forward pass\n",
    "time_series_data = torch.randn(batch_size, num_timesteps, cfg.dataset.node_sz)\n",
    "node_feature_data = torch.randn(batch_size, cfg.dataset.node_sz, cfg.dataset.node_feature_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e8852d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_feature_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "715324bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiheadAttention(\n",
       "  (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.attention_list[0].self_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59d363cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after Attention Layer 0: torch.Size([4, 10, 32])\n",
      "Output shape after Attention Layer 1: torch.Size([4, 10, 32])\n"
     ]
    }
   ],
   "source": [
    "current_features = node_feature_data\n",
    "for i, atten_layer in enumerate(model.attention_list):\n",
    "    # Pass the features through the current attention layer\n",
    "    current_features = atten_layer(current_features)\n",
    "    print(f\"Output shape after Attention Layer {i}: {current_features.shape}\")\n",
    "     # The shape should remain (batch_size, node_sz, node_feature_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63c95e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape after 'mean' readout: torch.Size([4, 32])\n"
     ]
    }
   ],
   "source": [
    "features_after_attention = current_features\n",
    "if cfg.model.readout == \"mean\":\n",
    "    readout_output = torch.mean(features_after_attention, dim=1)\n",
    "    print(f\"Features shape after '{cfg.model.readout}' readout: {readout_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7fbcb79",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TransformerEncoderLayer' object has no attribute 'get_attention_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_attention_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Yandex.Disk.localized/Projects/BrainIHBProjects/LabNeuroimagingProjects/DLfMRI/BrainNetworkTransformer/source/models/transformer.py:65\u001b[39m, in \u001b[36mGraphTransformer.get_attention_weights\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_attention_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43matten\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_attention_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43matten\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention_list\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Yandex.Disk.localized/Projects/BrainIHBProjects/LabNeuroimagingProjects/DLfMRI/BrainNetworkTransformer/source/models/transformer.py:65\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_attention_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43matten\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_attention_weights\u001b[49m() \u001b[38;5;28;01mfor\u001b[39;00m atten \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.attention_list]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Yandex.Disk.localized/Projects/BrainIHBProjects/LabNeuroimagingProjects/DLfMRI/BrainNetworkTransformer/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1688\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1687\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'TransformerEncoderLayer' object has no attribute 'get_attention_weights'"
     ]
    }
   ],
   "source": [
    "model.get_attention_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2301176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = TransformerEncoderLayer(d_model=512, nhead=2)\n",
    "src = torch.rand(10, 32, 512)\n",
    "out = encoder_layer(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dda524f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3fa2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
